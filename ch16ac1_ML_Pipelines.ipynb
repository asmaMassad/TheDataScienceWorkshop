{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Activity 16.01: Complete ML Workflow in a Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You have been assigned the task of doing an initial screening of patients based on their body parameters, such as cholesterol, blood pressure, pulse, and more.\n",
    "\n",
    "The aim of this activity is for you to predict whether a patient has a heart ailment using the patient parameters' dataset. To make the data science life cycle simple, you will be using an ML pipeline."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter16/Dataset/processed.cleveland.data'\n",
    "\n",
    "rawData = pd.read_csv(filename, sep=',', header=None, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  label  \n",
       "0    3.0  0.0   6.0      0  \n",
       "1    2.0  3.0   3.0      2  \n",
       "2    2.0  2.0   7.0      1  \n",
       "3    3.0  0.0   3.0      0  \n",
       "4    1.0  0.0   3.0      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.loc[rawData['label'] > 0, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(297, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "alteredData = rawData.dropna(axis=0) \n",
    "alteredData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  \n",
       "0    3.0  0.0   6.0  \n",
       "1    2.0  3.0   3.0  \n",
       "2    2.0  2.0   7.0  \n",
       "3    3.0  0.0   3.0  \n",
       "4    1.0  0.0   3.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "y = alteredData.pop('label')\n",
    "X = alteredData\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing Engine\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spot checking models\n",
    "classifiers = [LogisticRegression(random_state=123), KNeighborsClassifier(), RandomForestClassifier(random_state=123), AdaBoostClassifier(random_state=123)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(random_state=123) \n",
      " model score 0.7888888888888889\n",
      "--------\n",
      "KNeighborsClassifier() \n",
      " model score 0.7777777777777778\n",
      "--------\n",
      "RandomForestClassifier(random_state=123) \n",
      " model score 0.8333333333333334\n",
      "--------\n",
      "AdaBoostClassifier(random_state=123) \n",
      " model score 0.7222222222222222\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    estimator =Pipeline(steps=[('preprocessor', preprocessor), ('dimred', PCA(10)), ('classifier', classifier)])\n",
    "    estimator.fit(train_X, train_y)\n",
    "    print(classifier,'\\n model score',estimator.score(test_X, test_y))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline with Logistic Regression\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('dimred', PCA()),\n",
    "                           ('classifier',RandomForestClassifier(random_state=123))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'dimred__n_components':[10,11,12,13],\"classifier__n_estimators\": [50,100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = GridSearchCV(pipe, cv=10, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object'))])),\n",
       "                                       ('dimred', PCA()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=123))]),\n",
       "             param_grid={'classifier__n_estimators': [50, 100, 200],\n",
       "                         'dimred__n_components': [10, 11, 12, 13]})"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "best_estimator.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score 0.8221428571428572\nBest Params {'classifier__n_estimators': 50, 'dimred__n_components': 12}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score', best_estimator.best_score_)\n",
    "print('Best Params', best_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_estimator.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80        49\n           1       0.76      0.76      0.76        41\n\n    accuracy                           0.78        90\n   macro avg       0.78      0.78      0.78        90\nweighted avg       0.78      0.78      0.78        90\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[39 10]\n [10 31]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(predictions, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}